
<!DOCTYPE html>
<meta charset="utf-8">

<!-- Load d3.js -->
<script src="https://d3js.org/d3.v6.js"></script>
<script src="https://unpkg.com/d3-simple-slider"></script>
<script src="https://d3js.org/d3-color.v1.min.js"></script>
<script src="https://d3js.org/d3-hsv.v0.1.min.js"></script>

<head> 
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@500&display=swap" rel="stylesheet">
</head>

<main>
    <div>
        <div id="sections" style="width: 80%;">
            <div id="toc" class="toc" style="background-color: #989898; height: 100%;">
                <nav class="section-nav" >
                    <ol>
                        <li><a style="color:black">Jump to...</a></li> <p>
                        <li><a href="#top_">Top</a></li>
                        <li><a href="#intro_">Introduction</a></li>
                        <li><a href="#nns_">NNs</a></li>
                        <li><a href="#error_">Error</a></li>
                        <li><a href="#uq_">Uncertainty</a></li>
                        <li><a href="#attack_">Adv. Attacks</a></li>
                        <li><a href="#active_">Active Learning</a></li>
                        <li><a href="#references_">References</a></li>
                        <!-- <li><a href="#future_">Future Work</a></li> -->
                    </ol>
                </nav>
            </div>
            <section class="step" id="top_">
                <div style="text-align: center;">
                    <h1>
                        Tutorial: Differentiable Sampling of Molecular Geometries with Uncertainty-based Adversarial Attacks
                    </h1>
                    <p>
                        Daniel Schwalbe-Koda*
                    </p>  
                    <img style="padding-top: 30px; padding-bottom: 20px; width: 35%;" src="figs/intro/geometries.png"/>
                    <p style="color: grey;">&#8595; SCROLL TO BEGIN &#8595;</p>      
                    
                </div>
            </section>
            <section class="step s_small" id="intro_">
                <div style="width:40%;">
                    <h2>Understanding material behavior</h2>
                    <p>
                        A potential energy surface (PES) describes the energy of a system based on the configuration of atoms within it. PESes are crucial in the study of materials science for understanding how materials will behave under varying conditions. 
                    </p>
                    <p>
                        Creating accurate models of these PESes means we can discover and use better materials in many different applications--from characterizing drug activity and toxicity, to creating stronger steel compositions for spacecrafts!
                    </p>
                    <p>
                        Traditionally, computationally expensive methods such as ab initio simulations are used to map potential PESes. However, these methods quickly become prohibitive when a larger number of materials are screened. 
                    </p>
                    <p>
                        Recent advances in machine learning techniques allow for high-accuracy predictions in less time and at lower costs.
                    </p>
                </div>
            </section>
            <section class="step s_small" id="intro_question">
                <div style="width: 40%; font-size: 26px;">
                    <p><em>Let's take a look at how this works...</em></p>
                </div>
            </section>
            <section class="step" style="color: white;" id="intro_blank">""</section>


            <section class="step s_small flex-container" id="nns_">
                <div style="width: 40%">
                    <h2>Neural networks</h2>
                    <p>
                        One machine learning tool, the neural network (NN), is especially well suited to handle the extensive datasets needed to train PESes for complex materials. 
                    </p>
                    <p>
                        NNs is typically trained on data from quantum chemistry simulations, which are considered the "ground truth" result for these predictions. 
                    </p>
                    <p>
                        The trained neural network is then used to make predictions on that system's PES for any given geometry.
                    </p>
                </div>
            </section>
            <section class="step s_small flex-container" id="nns_question">
                <div style="width: 40%; font-size: 26px;">
                    <p><em>But are these predictions accurate?</em></p>
                </div>
            </section>
            <section class="step" style="color: white;" id="nns_blank">""</section>


            <section class="step flex-container" style="width:100%;" id="error_">
                <div style="width:40%;">
                    <h2>Prediction error in neural networks</h2>
                    <p>
                        There is always some error associated to NN predictions. Consider the neural network on the right, which classifies whether an input image represents a dog or a cat. 
                    </p>
                    <p>
                        Hover over the three different input photos to see what the NN predicts...
                    </p>
                   <div style="width: 90%; text-align: center;" class="flex-container">
                        <img id="cat" style="width: 28%;" src="figs/intro/cat.png"/>
                        <img id="dog" style="width: 28%;" src="figs/intro/dog.png"/>
                        <img id="bird" style="width: 28%;" src="figs/intro/bird.png"/>
                   </div>
                </div>
                <div style="width:60%; text-align: center; margin-top: 80px;">
                    <img id="animals" src="figs/intro/nn_hover.png" style="width:90%;"/>
                </div>
            </section>

            <section class="step flex-container" style="width:100%;" id="error_mol">
                <div style="width: 40%;">
                    <p>
                        Neural networks predicting PESes face similar challenges to those outlined in the example above. While the algorithm interpolates between existing data points very well (similar to the cat and dog), it may fail catastrophically for cases for which we have little to no data (similar to the bird).
                    </p>
                    <p>
                        Hover over the three different input geometries to see how the network makes a prediction under uncertainty:
                    </p>
                   <div style="width: 90%; text-align: center;" class="flex-container">
                        <img id="mol1" style="width: 28%;" src="figs/intro/mol1.png"/>
                        <img id="mol2" style="width: 28%;" src="figs/intro/mol2.png"/>
                        <img id="mol3" style="width: 28%;" src="figs/intro/mol3.png"/>
                   </div>
                </div>
                <div style="width:60%; text-align: center; margin-top: 80px;">
                    <img id="molnn" src="figs/intro/molnn_1.png" style="width:90%;"/>
                </div>
            </section>

            <section class="step" id="error_question">
                <div style="width: 40%; font-size: 26px;">
                    <p><em>One problem, therefore, is: how to assess the reliability of neural network predictions?</em></p>
                </div>
            </section>
            <section class="step" style="color: white;" id="error_blank">""</section>

            <section class="step" style="width:40%;" id="uq_">
                <h2>
                    Uncertainty Quantification
                </h2>
                    <p>
                        Instead of using a single neural network to make predictions, we can use an ensemble of neural networks. When the data is well-represented in the training set, the neural network committee predicts a single value with low uncertainty. On the other hand, when the data is not well-known, the NNs will disagree on the predicted property, thus leading to a higher uncertainty.
                    </p>
                    <p>
                        In the case of molecular simulation, it is more interesting to use uncertainty in the predicted forces instead of predicted energy. 
                    </p>
            </section>
            <section class="step" id="uq_question">
                <div style="width: 40%; font-size: 26px;">
                    <p><em>Now, the follow-up question: how do we improve the robustness of neural networks for atomistic simulations?</em></p>
                </div>
            </section>

            <section class="step" style="width:40%;" id="attack_">
                <h2>
                    Adversarial Attacks
                </h2>
                    <p>
                        Improving the robustness of neural network potentials requires increasing the breadth of their training sets; however, gathering this data usually requires time-consuming and costly simulations. It is therefore crucial to only gather data that will significantly improve the model's ability to make accurate predictions.
                    </p>
                <p>
                    We use the concept of adversarial attacks from the machine learning literature to find which molecular geometries the NNs fail to predict. In atomistic simulations, that corresponds to adding a small disturbance &delta; to the input geometry and finding which are the distortions that maximize the uncertainty of the neural network committee. 
                </p>
                <p> Next, we exemplify how this method works... </p>
            </section>
            <section class="step" style="color: white;" id="attack_blank">""</section>
        

            <section class="step" style="width:40%;" id="attack_ex">
                <h2>
                    Exemplifying adversarial attacks
                </h2>
                    <p>
                        Consider a 2D potential energy surface such as the one shown on the right. A toy example could be the 2D double well, which is a potential having two energy states. We can train a neural network committee to predict this potential energy surface and then analyze the energies and forces predicted by the committee.
                    </p>
            </section>


            <section class="step" style="width:40%;" id="attack_explain1">
                    <p>
                        Say that, after training the neural networks, we obtain the predictions and uncertainties on the right. The plot on the left indicates the mean energy predicted by the ensemble, while the plot on the right depicts a metric of uncertainty.
                    </p>
                    <p>
                        The neural networks were trained having very little information about the rightmost basin of the double well, but several data points on the left basin. As a consequence, the uncertainty is much higher on the right than on the left.
                    </p>
            </section>
            <section class="step" style="width:40%;" id="attack_explain2">
                    <p>
                        A point close to the training set is likely to have low uncertainty and a reliable PES. The NNs know this region well, and the committee agrees on which should be the predicted energy/forces.
                    </p>
            </section>
            <section class="step" style="width:40%;" id="attack_explain3">
                    <p>
                        An adversarial attack consists of distorting any predicted point to maximize the predicted uncertainty, i.e. the disagreement between the NNs. This point is likely to not be well-represented in the training set, and should be the most informative to calculate using more expensive methods. 
                    </p>
            </section>
            <section class="step" id="attack_question">
                <div style="width: 40%; font-size: 26px;">
                    <p><em>How do we incorporate the information learned from adversarial attacks back into the original model?</em></p>
                </div>
            </section>
            <section class="step" style="width:40%;" id="active_">
                <h2>Active Learning</h2>
                    <p>
                        To improve the performance of the neural network predictions, we can repeat this process in what is called an active learning loop. We start by gathering the data from a training set and training the NNs. Then, we find which are the points that maximize the committee uncertainty and send the new data for evaluation. By repeating this process, we successively improve the predictions of the NNs for the PES without human intervention.
                    </p>
            </section>

            <section class="step" style="width:40%;" id="active_evolution">   
                <p>
                    As we execute the loop iteratively, the neural networks predict a better potential energy surface and the overall predicted uncertainty gets lower. The figure shows the evolution of the predictions, the training points points and adversarial attacks.
                </p>

                <div>
                    <p>
                        Change the slider below to see how the PES evolves with the number of times the loop is executed (active learning generation).
                    </p>
                    <p>
                        <svg id='slider'></svg> 
                    </p>          
                </div>    
            </section>
            <section class="step" style="color: white;" id="active_blank">""</section>

            <section class="step" style="width:40%;" id="active_performance">   
                <p>
                    We can perform this active learning loop several times and verify whether the adversarial sampling strategy is useful or not. The plot on the right compares the root mean square error (RMSE), number of sampled points, and the energy of the points on the PES according to their sampling method (attack or random). 100 independent loops were run to compare both methods. The shaded area indicates the interquartile range, and the solid line is the median performance of each experiment.
                </p>
                <p>
                    The graphs indicate that the adversarial sampling strategy outperforms random sampling in all aspects under comparison: the final NNs are more accurate (RMSE ~3 times smaller); less points are sampled; and the energy of the sampled points is smaller, suggesting the attacks lead to configurations more meaningful at lower temperatures.
               </p>

            </section>


            <section class="step" style="width:40%;" id="references_">
                <h2>
                    References
                </h2>
                    <p>
                    This visualization was based on the data from the following paper: <br>

                        D. Schwalbe-Koda, A.R. Tan, R. Gómez-Bombarelli. 
                        <a href="https://doi.org/10.1038/s41467-021-25342-8" target="_blank">Differentiable sampling of molecular geometries with uncertainty-based adversarial attacks.</a> <i>Nature Communications</i> <b>12</b>, 5104 (2021).
                    </p>
                    <p>
                        The visualization of the NN classifier for cats/dogs was based on <a href="https://www.inovex.de/blog/uncertainty-quantification-deep-learning/">a post by S. Bachstein</a>.
                        </p>
                    <p>
                        *Scrolly-telling story made by Aik Jun Tan, Daniel Schwalbe-Koda, and Franklin Morgan as a final project for the 6.859 MIT class (Spring 2021).
                    </p>
            </section>

            </div>


            <svg id="svgBlank" class = "visuals"></svg>
            <svg id='svgIntro1' viewBox = "-175 -10 400 400" class = "visuals"></svg>
            <svg id='svgIntro2' viewBox = "-230 -50 650 650" class = "visuals"></svg>
            <svg id='svgIntro3' viewBox = "-1600 -500 3500 3500" class = "visuals"></svg>
            <svg id='svgIntro3Cat' viewBox = "-1600 -500 3500 3500" class = "visuals"></svg>
            <svg id='svgIntro3Dog' viewBox = "-1600 -500 3500 3500" class = "visuals"></svg>
            <svg id='svgIntro3Bird' viewBox = "-1600 -500 3500 3500" class = "visuals"></svg>
            <svg id='svgIntro4' viewBox = "-1600 -500 3500 3500" class = "visuals"></svg>
            <svg id='svgIntro4_1' viewBox = "-1600 -500 3500 3500" class = "visuals"></svg>
            <svg id='svgIntro4_2' viewBox = "-1600 -500 3500 3500" class = "visuals"></svg>
            <svg id='svgIntro4_3' viewBox = "-1600 -500 3500 3500" class = "visuals"></svg>
            <svg id='svgUncertainty1' viewBox = "-1500 -500 4000 4000" class = "visuals"></svg>
            <svg id='svgUncertainty2' viewBox = "-1500 -500 4000 4000" class = "visuals"></svg>
            <svg id='svgUncertainty3' viewBox = "-1500 -500 4000 4000" class = "visuals"></svg>
            <svg id='svgAttacks1' viewBox = "-2000 -400 5500 2750" class = "visuals"></svg>
            <svg id='svgAttacks2' viewBox = "-2750 -600 7250 2500" class = "visuals"></svg>
            <svg id='svgAttacks3' viewBox = "-2750 -600 7250 2500" class = "visuals"></svg>
            <svg id='svgAttacks4' viewBox = "-2750 -600 7250 2500" class = "visuals"></svg>
            <svg id='svgLoop1' viewBox = "-1200 -200 2500 2500" class = "visuals"></svg>
            
            <svg id='svg1' viewBox = "-2750 -600 7250 2500" class = "visuals"></svg>
            <svg id='svg2' viewBox = "-2750 -600 7250 2500" class = "visuals"></svg>
            <svg id='svg3' viewBox = "-2750 -600 7250 2500" class = "visuals"></svg>
            <svg id='svg4' viewBox = "-2750 -600 7250 2500" class = "visuals"></svg>
            <svg id='svg5' viewBox = "-2750 -600 7250 2500" class = "visuals"></svg>
            <svg id='svg6' viewBox = "-2750 -600 7250 2500" class = "visuals"></svg>
            <svg id='svg7' viewBox = "-2750 -600 7250 2500" class = "visuals"></svg>
            
            <svg id='svgActivePerf' viewBox = "-1100 -200 2500 2500" class = "visuals"></svg>

            <!-- <svg id='svgEnd' class = "visuals"></svg> -->

    </div>
</main>

<script src="scripts/scenes/base.js"></script>
<script src="scripts/scenes/title.js"></script>
<script src="scripts/scenes/svg.js"></script>
<script src="scripts/scenes/contour.js"></script>
<script src="scripts/sections/config.js"></script>
<script src="scripts/sections/title.js"></script>
<script src="scripts/sections/intro.js"></script>
<script src="scripts/sections/explanation.js"></script>
<script src="scripts/sections/evolution.js"></script>
<script src="scripts/scenes.js"></script>
<script src="scripts/scroller.js"></script>
<script src="scripts/scenes/hover.js"></script>
<script src="scripts/toc.js"> </script>
